{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a132959-f7ce-40b9-a02f-1a69a7fce9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PadID  Size X  Size Y  Volume  OffsetX  OffsetY  PCB ID  Printing Speed  \\\n",
      "0      1     220     220  74.447   -9.990    5.766     241              30   \n",
      "1      2     220     220  84.224  -15.069   17.116     241              30   \n",
      "2      3     220     220  77.646   -5.895    5.528     241              30   \n",
      "3      4     220     220  79.544  -11.337    8.486     241              30   \n",
      "4      5     220     220  79.548  -13.730    8.963     241              30   \n",
      "\n",
      "   Printing Pressure  Separation Speed Cleaning Type  Cleaning Age Direction  \\\n",
      "0                 60               3.0           Wet             1         F   \n",
      "1                 60               3.0           Wet             1         F   \n",
      "2                 60               3.0           Wet             1         F   \n",
      "3                 60               3.0           Wet             1         F   \n",
      "4                 60               3.0           Wet             1         F   \n",
      "\n",
      "   Pos X    Pos Y  Rotation      AR   ASR  \n",
      "0  31260  40080.0        90  0.6875  2.75  \n",
      "1  31260  39700.0        90  0.6875  2.75  \n",
      "2  31830  40080.0        90  0.6875  2.75  \n",
      "3  31830  39700.0        90  0.6875  2.75  \n",
      "4  32400  40080.0        90  0.6875  2.75  \n",
      "   Volume  OffsetX  OffsetY  PCB ID  Printing Speed  Printing Pressure  \\\n",
      "0  74.447   -9.990    5.766     241              30                 60   \n",
      "1  84.224  -15.069   17.116     241              30                 60   \n",
      "2  77.646   -5.895    5.528     241              30                 60   \n",
      "3  79.544  -11.337    8.486     241              30                 60   \n",
      "4  79.548  -13.730    8.963     241              30                 60   \n",
      "\n",
      "   Separation Speed  Cleaning Type  Cleaning Age  Direction  Pos X    Pos Y  \\\n",
      "0               3.0              1             1          1  31260  40080.0   \n",
      "1               3.0              1             1          1  31260  39700.0   \n",
      "2               3.0              1             1          1  31830  40080.0   \n",
      "3               3.0              1             1          1  31830  39700.0   \n",
      "4               3.0              1             1          1  32400  40080.0   \n",
      "\n",
      "   Rotation  Size  \n",
      "0        90     0  \n",
      "1        90     0  \n",
      "2        90     0  \n",
      "3        90     0  \n",
      "4        90     0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pywt\n",
    "from scipy.signal import savgol_filter, medfilt\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.restoration import denoise_wavelet\n",
    "from cv2 import bilateralFilter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('PrinterSimulatorDataset.csv', low_memory=False)\n",
    "data.columns = data.columns.str.strip()\n",
    "print(data.head())\n",
    "\n",
    "\n",
    "# ðŸ‘£ FEATURE ENGINEERING\n",
    "def map_size(x):\n",
    "    if x == 220:\n",
    "        return 'Small'\n",
    "    elif x == 330:\n",
    "        return 'Medium'\n",
    "    elif x == 560:\n",
    "        return 'Large'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "if 'Size X' in data.columns:\n",
    "    data['Size'] = data['Size X'].apply(map_size)\n",
    "    data.drop(columns=['Size X', 'Size Y', 'AR', 'ASR','PadID'], inplace=True, errors='ignore')\n",
    "else:\n",
    "    print(\"Warning: 'Size X' not found.\")\n",
    "    data['Size'] = 'Unknown'\n",
    "\n",
    "size_map = {'Small': 0, 'Medium': 1, 'Large': 2, 'Unknown': -1}\n",
    "data['Size'] = data['Size'].map(size_map)\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_cols = ['Cleaning Type', 'Direction', 'Size']\n",
    "le = LabelEncoder()\n",
    "for col in categorical_cols:\n",
    "    if col in data.columns:\n",
    "        data[col] = le.fit_transform(data[col].astype(str))\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "# Define features and targets\n",
    "targets = ['Volume', 'OffsetX', 'OffsetY']\n",
    "features = list(data.columns.difference(targets))\n",
    "\n",
    "X = data[features]\n",
    "y = data[targets]\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f928eff6-19d3-4c91-94d9-79e96db47612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         MAE                    RMSE          \\\n",
      "Target Variable                      OffsetX OffsetY  Volume OffsetX OffsetY   \n",
      "Filter 1 Filter 2       Filter 3                                               \n",
      "DTCWT    Savitzky-Golay Bilateral     0.0467  0.0202  0.0589  0.0866  0.0407   \n",
      "                        Gaussian      0.0552  0.0237  0.0690  0.0960  0.0431   \n",
      "                        Median        0.0595  0.0256  0.0739  0.0999  0.0451   \n",
      "                        Multivariate  0.0510  0.0219  0.0642  0.0922  0.0414   \n",
      "\n",
      "                                              \n",
      "Target Variable                       Volume  \n",
      "Filter 1 Filter 2       Filter 3              \n",
      "DTCWT    Savitzky-Golay Bilateral     0.1027  \n",
      "                        Gaussian      0.1144  \n",
      "                        Median        0.1209  \n",
      "                        Multivariate  0.1096  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pywt\n",
    "from scipy.signal import savgol_filter, medfilt\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from cv2 import bilateralFilter\n",
    "\n",
    "# Define filters (including your new ones)\n",
    "def apply_dtcwt_filter(signal):\n",
    "    coeffs = pywt.wavedec(signal, 'db4', level=1)\n",
    "    coeffs[1:] = [np.zeros_like(i) for i in coeffs[1:]]\n",
    "    return pywt.waverec(coeffs, 'db4')[:len(signal)]\n",
    "\n",
    "def apply_median_filter(signal):\n",
    "    return medfilt(signal, kernel_size=3)\n",
    "\n",
    "def apply_gaussian_filter(signal):\n",
    "    return gaussian_filter(signal, sigma=1)\n",
    "\n",
    "def apply_savgol_filter(signal):\n",
    "    window_length = min(len(signal) if len(signal) % 2 == 1 else len(signal)-1, 21)\n",
    "    return savgol_filter(signal, window_length=window_length, polyorder=2)\n",
    "\n",
    "def apply_bilateral_filter(signal):\n",
    "    return bilateralFilter(signal.astype(np.float32), 9, 75, 75)\n",
    "\n",
    "def apply_multivariate_filter(signal):\n",
    "    kernel = np.ones(5)/5\n",
    "    return np.convolve(signal, kernel, mode='same')\n",
    "\n",
    "# Map filters to functions\n",
    "filter_functions = {\n",
    "    'DTCWT': apply_dtcwt_filter,\n",
    "    'Gaussian': apply_gaussian_filter,\n",
    "    'Median': apply_median_filter,\n",
    "    'Savitzky-Golay': apply_savgol_filter,\n",
    "    'Bilateral': apply_bilateral_filter,\n",
    "    'Multivariate': apply_multivariate_filter,\n",
    "}\n",
    "\n",
    "# Your specific filter combinations to try (order matters)\n",
    "filter_orders = [\n",
    "    ('DTCWT', 'Savitzky-Golay', 'Median'),\n",
    "    ('DTCWT', 'Savitzky-Golay', 'Gaussian'),\n",
    "    ('DTCWT', 'Savitzky-Golay', 'Bilateral'),\n",
    "    ('DTCWT', 'Savitzky-Golay', 'Multivariate'),\n",
    "]\n",
    "\n",
    "# Standard scalers\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "# Training and evaluation function\n",
    "def train_evaluate_model(model, model_name, X_train, X_test, y_train, y_test):\n",
    "    results = []\n",
    "    for i, target in enumerate(targets):\n",
    "        model.fit(X_train, y_train[:, i])\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        rmse = np.sqrt(mean_squared_error(y_test[:, i], y_pred))\n",
    "        mae = mean_absolute_error(y_test[:, i], y_pred)\n",
    "\n",
    "        results.append([model_name, target, rmse, mae])\n",
    "    return results\n",
    "\n",
    "# Initialize model\n",
    "dt_model = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Collect results\n",
    "all_results = []\n",
    "for order in filter_orders:\n",
    "    filtered_data = y.copy()\n",
    "\n",
    "    for col in targets:\n",
    "        signal = y[col].values.copy()\n",
    "        for filter_name in order:\n",
    "            signal = filter_functions[filter_name](signal)\n",
    "        filtered_data[col] = signal\n",
    "\n",
    "    # Scale features and targets\n",
    "    X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "    X_test_scaled = scaler_X.transform(X_test)\n",
    "    y_train_scaled = scaler_y.fit_transform(filtered_data.loc[y_train.index])\n",
    "    y_test_scaled = scaler_y.transform(filtered_data.loc[y_test.index])\n",
    "\n",
    "    results_dt = train_evaluate_model(dt_model, \"Decision Tree\", X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled)\n",
    "\n",
    "    for row in results_dt:\n",
    "        all_results.append(order + tuple(row))  # (filter1, filter2, filter3, model, target, rmse, mae)\n",
    "\n",
    "# Create results dataframe\n",
    "columns = ['Filter 1', 'Filter 2', 'Filter 3', 'Model', 'Target Variable', 'RMSE', 'MAE']\n",
    "results_df = pd.DataFrame(all_results, columns=columns)\n",
    "\n",
    "# Print pivot table\n",
    "print(results_df.pivot_table(index=['Filter 1', 'Filter 2', 'Filter 3'],\n",
    "                             columns='Target Variable',\n",
    "                             values=['RMSE', 'MAE']).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b83550-25e5-45be-8895-a57cf015aeb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
